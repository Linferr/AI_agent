# High-Level：这个 repo 在做什么（以及怎么做）

这份文档用于：
- 快速对齐概念、边界与术语
- 给项目一个可执行的分阶段路线图（每阶段都有“可验收”的产出）

## 1. 概念地图（从底向上叠）

常见的关键词包括：`LLM`、`RAG`、`Tool/Function Calling`、`Agent`、`MCP`、`Skills`、`Observability/Evaluation`。

它们更像“能力栈”：

```
┌──────────────────────────────┐
│ Agent / Multi-step System    │  多步规划与执行（循环）
├──────────────────────────────┤
│ Tool Calling / Skills        │  让模型能调用外部能力
├──────────────────────────────┤
│ RAG / Memory / Context       │  让回答基于可控外部知识
├──────────────────────────────┤
│ LLM + Prompting              │  让系统能对话与推理
└──────────────────────────────┘
```

建设顺序也应按这个顺序：先把底座做稳，再加上层。

## 2. 关键概念（工程视角）

下面每一条都对应未来代码里的一块“职责”和“接口”。

### 2.1 LLM：把它当成一个远程服务

关注点不是训练细节，而是工程约束：
- 输入：`prompt/messages` 如何组织
- 输出：文本/结构化 JSON/工具调用
- 失败：超时、重试、幻觉与兜底策略
- 成本与延迟：token、并发、缓存

建议在代码里形成一个明确边界：`call_llm(messages) -> response`。

### 2.2 RAG：把“你控制的知识”放进上下文

最小闭环 4 步：
1) 文档切分（chunk）
2) 向量化（embedding）
3) 检索（相似度/过滤）
4) 组装上下文并生成回答（grounded answer）

RAG 的目标是减少“瞎编”，让回答可追溯到具体证据片段。

### 2.3 Tool Calling / Skills：让系统能“做事”

核心不是“能调 API”，而是把工具变成可控能力：
- 定义工具输入输出（schema）
- 参数校验与权限边界
- 失败处理（重试、降级、超时）
- 把工具结果回填给 LLM（形成闭环）

`Skills` 可以理解为“更高层的可复用工具流程/封装”。

### 2.4 Agent：不是魔法，是一个受控的循环

Agent 不是“更强的模型”，而是“规划 + 执行 + 观察”的循环逻辑（典型 ReAct）：

```
while not done:
  plan next step
  call a tool (or answer)
  observe result
```

工程上要解决的是：步数上限、终止条件、防止死循环、失败兜底、状态管理。

### 2.5 Observability & Evaluation：把系统从“能跑”变成“可改进”

- 可观测性：每一步耗时、token、错误率、工具调用统计、关键中间产物（如检索命中）
- 可评估性：固定测试集/用例，能对比 prompt、检索策略、工具策略的效果变化

